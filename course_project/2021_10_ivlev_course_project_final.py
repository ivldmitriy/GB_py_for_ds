# -*- coding: utf-8 -*-
"""2021.10_ivlev_course_project_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DAjDipACNVDm7mvDIJ4M_Asc2Iql3eB2

#Курсовой проект
##Д.А. Ивлев

## 1. Описание скрпитов, импорт библиотек и загрузка данных  <a class='anchor' id='preparation'>

###Подключение библиотек
"""

# Импортируем базовые бибилиотеки
import numpy as np
import pandas as pd
import random
from datetime import datetime

# Импортируем модули из библиотеки scikit-learn
from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import r2_score as r2, mean_absolute_error as mae, mean_squared_error as mse, roc_auc_score as auc
from sklearn.tree import DecisionTreeRegressor

# Commented out IPython magic to ensure Python compatibility.
# Импортируем и настраиваем модули для отрисовки графиков
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
matplotlib.rcParams.update({'font.size': 14})
# %config InlineBackend.figure_format = 'svg'
# %matplotlib inline

import warnings
warnings.filterwarnings('ignore')

"""###Описание скриптов"""

def evaluate_preds(train_true_values, train_pred_values, test_true_values, test_pred_values):
    print("Train R2:\t" + str(round(r2(train_true_values, train_pred_values), 3)))
    print("Test R2:\t" + str(round(r2(test_true_values, test_pred_values), 3)))
    
    plt.figure(figsize=(9,3))
    
    plt.subplot(121)
    sns.scatterplot(x=train_pred_values, y=train_true_values)
    plt.xlabel('Predicted values')
    plt.ylabel('True values')
    plt.title('Train sample prediction')
    
    plt.subplot(122)
    sns.scatterplot(x=test_pred_values, y=test_true_values)
    plt.xlabel('Predicted values')
    plt.ylabel('True values')
    plt.title('Test sample prediction')

    plt.show()

"""###Загрузка данных

**Описание датасета**

* **Id** - идентификационный номер квартиры
* **DistrictId** - идентификационный номер района
* **Rooms** - количество комнат
* **Square** - площадь
* **LifeSquare** - жилая площадь
* **KitchenSquare** - площадь кухни
* **Floor** - этаж
* **HouseFloor** - количество этажей в доме
* **HouseYear** - год постройки дома
* **Ecology_1, Ecology_2, Ecology_3** - экологические показатели местности
* **Social_1, Social_2, Social_3** - социальные показатели местности
* **Healthcare_1, Helthcare_2** - показатели местности, связанные с охраной здоровья
* **Shops_1, Shops_2** - показатели, связанные с наличием магазинов, торговых центров
* **Price** - цена квартиры
"""

from google.colab import drive
drive.mount('/content/drive')

TRAIN_DATASET_PATH = '/content/drive/My Drive/_ML/GB/5_py_alg/webinar6/train.csv'
TEST_DATASET_PATH = '/content/drive/My Drive/_ML/GB/5_py_alg/webinar6/test.csv'

train_df = pd.read_csv(TRAIN_DATASET_PATH)
train_df.head(10)

test_df = pd.read_csv(TEST_DATASET_PATH)
test_df.head(10)

"""###Приведение типов"""

train_df.dtypes

test_df.dtypes

print('Строк в трейне:', train_df.shape[0])
print('Строк в тесте', test_df.shape[0])

"""* Id не кажется признаком, пригодным для построения модели
* DistrictId не кажется признаком, пригодным для построения модели

Приводим их тип к строковому!
"""

train_df['Id'] = train_df['Id'].astype(str)
train_df['DistrictId'] = train_df['DistrictId'].astype(str)

"""## 2. EDA  <a class='anchor' id='eda'>

####**Целевая переменная**
"""

plt.figure(figsize = (12, 6))

train_df['Price'].hist(bins=50)
plt.ylabel('Count')
plt.xlabel('Price')

plt.title('Target distribution')
plt.show()

"""####**Количественные переменные**"""

train_df.describe()

"""###2.1 Исправление выбросов <a class='anchor' id='outlier'>

####'**Rooms**'
"""

train_df['Rooms'].value_counts()

train_df['Rooms_outlier'] = 0
train_df.loc[(train_df['Rooms'] == 0) | (train_df['Rooms'] >= 6), 'Rooms_outlier'] = 1

train_df.loc[train_df['Rooms'] == 0, 'Rooms'] = 1
train_df.loc[train_df['Rooms'] >= 6, 'Rooms'] = train_df['Rooms'].median()

train_df['Square'].value_counts()

condition = (train_df['Square'].isna()) \
             | (train_df['Square'] > train_df['Square'].quantile(.975))

train_df.loc[condition, 'Square'] = train_df['Square'].median()
train_df.loc[train_df['Square'] < train_df['KitchenSquare'] + train_df['LifeSquare'], 'Square'] = train_df['KitchenSquare'] + train_df['LifeSquare']

"""####'**LifeSquare**'

"""

train_df['LifeSquare'].value_counts()

condition = (train_df['LifeSquare'].isna()) \
             | (train_df['LifeSquare'] > train_df['LifeSquare'].quantile(.975))
        
train_df.loc[condition, 'LifeSquare'] = train_df['LifeSquare'].median()
train_df.loc[train_df['LifeSquare'] < 6, 'LifeSquare'] = 6 # согласно законодательству РФ

"""####'**KitchenSquare**'"""

train_df['KitchenSquare'].value_counts()

condition = (train_df['KitchenSquare'].isna()) \
             | (train_df['KitchenSquare'] > train_df['KitchenSquare'].quantile(.975))
        
train_df.loc[condition, 'KitchenSquare'] = train_df['KitchenSquare'].median()
train_df.loc[train_df['KitchenSquare'] < 1, 'KitchenSquare'] = 1

"""####**'Square'**"""

train_df['Square'].value_counts()

condition = (train_df['Square'].isna()) \
             | (train_df['Square'] > train_df['Square'].quantile(.975))

train_df.loc[condition, 'Square'] = train_df['Square'].median()
train_df.loc[train_df['Square'] < train_df['KitchenSquare'] + train_df['LifeSquare'], 'Square'] = train_df['KitchenSquare'] + train_df['LifeSquare']

"""####**'HouseFloor', 'Floor'**"""

train_df['HouseFloor'].sort_values().unique()

train_df['Floor'].sort_values().unique()

train_df['HouseFloor_outlier'] = 0
train_df.loc[train_df['HouseFloor'] == 0, 'HouseFloor_outlier'] = 1
train_df.loc[train_df['HouseFloor'] == 0, 'HouseFloor'] = train_df['HouseFloor'].median()
train_df.loc[train_df['Floor'] > train_df['HouseFloor'], 'HouseFloor_outlier'] = 1

floor_outliers = train_df.loc[train_df['HouseFloor_outlier'] == 1].index

train_df.loc[floor_outliers, 'Floor'] = train_df.loc[floor_outliers, 'HouseFloor']\
                                                .apply(lambda x: random.randint(1, x))

"""####**'HouseYear'**"""

train_df['HouseYear'].sort_values(ascending=False)

train_df.loc[train_df['HouseYear'] > 2020, 'HouseYear'] = 2020

"""###2.2 Заполнение пропусков <a class='anchor' id='nan'>"""

train_df.isna().sum()

"""####**'Healthcare_1'**"""

train_df.drop('Healthcare_1', axis=1, inplace=True)

"""###2.3 Data Preprocessing <a class='anchor' id='preprocessing'>
Соберем все проведенные нами процедуры в методы класса
"""

class DataPreprocessing:
    """Подготовка исходных данных"""

    def __init__(self):
        """Параметры класса"""
        self.medians=None
        self.kitchen_square_quantile = None
        
    def fit(self, X):
        """Сохранение статистик"""       
        # Расчет медиан и квантилей
        self.medians = X.median()
        n = 0.975
        self.kitchen_square_quantile = X['KitchenSquare'].quantile(n)
        self.life_square_quantile = X['LifeSquare'].quantile(n)
        self.square_quantile = X['Square'].quantile(n)
    
    def transform(self, X):
        """Трансформация данных"""

        # Rooms
        X['Rooms_outlier'] = 0
        X.loc[(X['Rooms'] == 0) | (X['Rooms'] >= 6), 'Rooms_outlier'] = 1
        X.loc[X['Rooms'] == 0, 'Rooms'] = 1
        X.loc[X['Rooms'] >= 6, 'Rooms'] = self.medians['Rooms']

        # LifeSquare
        condition = (X['LifeSquare'].isna()) \
                    | (X['LifeSquare'] > self.life_square_quantile)
        X.loc[condition, 'LifeSquare'] = self.medians['LifeSquare']
        X.loc[X['LifeSquare'] < 6, 'LifeSquare'] = 6

        # KitchenSquare
        condition = (X['KitchenSquare'].isna()) \
                    | (X['KitchenSquare'] > self.kitchen_square_quantile)
        X.loc[condition, 'KitchenSquare'] = self.medians['KitchenSquare']
        X.loc[X['KitchenSquare'] < 3, 'KitchenSquare'] = 3
        
        # Square
        condition = (X['Square'].isna()) \
                    | (X['Square'] > self.square_quantile)
        X.loc[condition, 'Square'] = self.medians['Square']
        X.loc[X['Square'] < X['KitchenSquare'] + X['LifeSquare'], 'Square'] = X['KitchenSquare'] + X['LifeSquare']
        
        # HouseFloor, Floor
        X['HouseFloor_outlier'] = 0
        X.loc[X['HouseFloor'] == 0, 'HouseFloor_outlier'] = 1
        X.loc[X['Floor'] > X['HouseFloor'], 'HouseFloor_outlier'] = 1
        X.loc[X['HouseFloor'] == 0, 'HouseFloor'] = self.medians['HouseFloor']
        floor_outliers = X.loc[X['HouseFloor_outlier'] == 1].index
        X.loc[floor_outliers, 'Floor'] = X.loc[floor_outliers, 'HouseFloor']\
                                            .apply(lambda x: random.randint(1, x))
        
        # HouseYear
        current_year = datetime.now().year
        X['HouseYear_outlier'] = 0
        X.loc[X['HouseYear'] > current_year, 'HouseYear_outlier'] = 1
        X.loc[X['HouseYear'] > current_year, 'HouseYear'] = current_year
        # Healthcare_1
        if 'Healthcare_1' in X.columns:
            X.drop('Healthcare_1', axis=1, inplace=True)

        # Final check
        X.fillna(self.medians, inplace=True)
        
        return X

"""###2.4 Генерация новых признаков <a class='anchor' id='feature'>

####**Dummies**
"""

binary_to_numbers = {'A': 0, 'B': 1}
train_df['Ecology_2'] = train_df['Ecology_2'].replace(binary_to_numbers)
train_df['Ecology_3'] = train_df['Ecology_3'].replace(binary_to_numbers)
train_df['Shops_2'] = train_df['Shops_2'].replace(binary_to_numbers)

"""####**DistrictSize, IsDistrictLarge**"""

district_size = train_df['DistrictId'].value_counts().reset_index()\
                    .rename(columns={'index':'DistrictId', 'DistrictId':'DistrictSize'})
train_df = train_df.merge(district_size, on='DistrictId', how='left')
train_df['IsDistrictLarge'] = (train_df['DistrictSize'] > 100).astype(int)
train_df.head()

"""####**MedPriceByDistrict**"""

med_price_by_district = train_df.groupby(['DistrictId', 'Rooms'], as_index=False).agg({'Price':'median'})\
                            .rename(columns={'Price':'MedPriceByDistrict'})
train_df = train_df.merge(med_price_by_district, on=['DistrictId', 'Rooms'], how='left')

"""####**DistrictAge, IsDistrictNew**"""

district_age = train_df.groupby(['DistrictId'], as_index=False).agg({'HouseYear':'median'}).\
                                            rename(columns={'HouseYear':'DistrictAge'})
train_df = train_df.merge(district_age, on='DistrictId', how='left')
train_df['IsDistrictNew'] = (train_df['DistrictAge'] > 2000).astype(int)
train_df.head()

"""####**MedPriceByFloorYear**"""

#Разбиение объектов  на категории в зависимости от этажа
def floor_to_cat(X):
    X['floor_cat'] = 0
    X.loc[X['Floor'] == 1, 'floor_cat'] = 1  
    X.loc[X['Floor'] == 2, 'floor_cat'] = 2
    X.loc[(X['Floor'] > 2) & (X['Floor'] <= 7), 'floor_cat'] = 3
    X.loc[(X['Floor'] > 7) & (X['Floor'] <= 15), 'floor_cat'] = 4
    X.loc[X['Floor'] > 15, 'floor_cat'] = 5
    X.loc[X['Floor'] == X['HouseFloor'], 'floor_cat'] = 6
    return X

#Разбиение объектов  на категории в зависимости от года постройки дома
def year_to_cat(X):
    X['year_cat'] = 0
    X.loc[X['HouseYear'] <= 1957, 'year_cat'] = 1
    X.loc[(X['HouseYear'] > 1957) & (X['HouseYear'] <= 1968), 'year_cat'] = 2
    X.loc[(X['HouseYear'] > 1968) & (X['HouseYear'] <= 1975), 'year_cat'] = 3
    X.loc[(X['HouseYear'] > 1975) & (X['HouseYear'] <= 1990), 'year_cat'] = 4
    X.loc[(X['HouseYear'] > 1990) & (X['HouseYear'] <= 2009), 'year_cat'] = 5
    X.loc[(X['HouseYear'] > 2009), 'year_cat'] = 6
    return X

train_df = floor_to_cat(train_df)
train_df = year_to_cat(train_df)
train_df.head()

med_price_by_floor_year = train_df.groupby(['year_cat', 'floor_cat'], as_index=False).agg({'Price':'median'}).\
                                            rename(columns={'Price':'MedPriceByFloorYear'})
train_df = train_df.merge(med_price_by_floor_year, on=['year_cat', 'floor_cat'], how='left')
train_df.head()

"""####**Square fractions**"""

train_df['LifeSquareFrac'] = train_df['LifeSquare']/train_df['Square']
train_df['KitchenSquareFrac'] = train_df['KitchenSquare']/train_df['Square']
train_df['LifeKitchenBalance'] = train_df['KitchenSquare']/train_df['LifeSquare']
train_df.head()

"""###2.5 Стандартизация признаков <a class='anchor' id='feature_scaling'>"""

train_df.dtypes

#StandardScaler, RobustScaler

all_feature_names = list(train_df.columns)
feature_names_for_stand = train_df[all_feature_names].select_dtypes(include=['float64', 'float32', 'float16']).columns.tolist()

scaler = RobustScaler()
stand_features = scaler.fit_transform(train_df[feature_names_for_stand])

train_df[feature_names_for_stand] = pd.DataFrame(stand_features, columns=feature_names_for_stand)

train_df.head()

train_df.dtypes

"""###2.6 Feature Generator <a class='anchor' id='generator'>"""

class FeatureGenetator():
    """Генерация новых признаков"""
    
    def __init__(self):
        self.DistrictId_counts = None
        self.binary_to_numbers = None
        self.med_price_by_district = None
        self.med_price_by_floor_year = None
        
    def fit(self, X, y=None):
        X = X.copy()
        # Binary features
        self.binary_to_numbers = {'A': 0, 'B': 1}
        # DistrictID
        self.district_size = X['DistrictId'].value_counts().reset_index()\
                              .rename(columns={'index':'DistrictId', 'DistrictId':'DistrictSize'})
        self.district_age = X.groupby(['DistrictId'], as_index=False).agg({'HouseYear':'median'})\
                              .rename(columns={'HouseYear':'DistrictAge'})

        # Target encoding
        ## District, Rooms
        df = X.copy()
        if y is not None:
            df['Price'] = y.values
            self.med_price_by_district = df.groupby(['DistrictId', 'Rooms'], as_index=False).agg({'Price':'median'})\
                                            .rename(columns={'Price':'MedPriceByDistrict'})
            self.med_price_by_district_median = self.med_price_by_district['MedPriceByDistrict'].median()
        ## floor, year
        if y is not None:
            df['Price'] = y.values
            df = self.floor_to_cat(df)
            df = self.year_to_cat(df)
            self.med_price_by_floor_year = df.groupby(['year_cat', 'floor_cat'], as_index=False).agg({'Price':'median'})\
                                            .rename(columns={'Price':'MedPriceByFloorYear'})
            self.med_price_by_floor_year_median = self.med_price_by_floor_year['MedPriceByFloorYear'].median()
        

        
    def transform(self, X):
        # Binary features
        X['Ecology_2'] = X['Ecology_2'].map(self.binary_to_numbers)  # self.binary_to_numbers = {'A': 0, 'B': 1}
        X['Ecology_3'] = X['Ecology_3'].map(self.binary_to_numbers)
        X['Shops_2'] = X['Shops_2'].map(self.binary_to_numbers)
        # DistrictId, IsDistrictLarge
        X = X.merge(self.district_size, on='DistrictId', how='left')
        X = X.merge(self.district_age, on='DistrictId', how='left')
        X['DistrictSize'].fillna(5, inplace=True)
        current_year = datetime.now().year
        X['DistrictAge'].fillna(current_year, inplace=True)
        X['IsDistrictLarge'] = (X['DistrictSize'] > 100).astype(int)
        X['IsDistrictNew'] = (X['DistrictAge'] > 2000).astype(int)
        # Square fractions
        X['LifeSquareFrac'] = X['LifeSquare']/X['Square']
        X['KitchenSquareFrac'] = X['KitchenSquare']/train_df['Square']
        X['LifeKitchenBalance'] = X['KitchenSquare']/X['LifeSquare']
        # More categorical features
        X = self.floor_to_cat(X)  # + столбец floor_cat
        X = self.year_to_cat(X)   # + столбец year_cat
        # Target encoding
        if self.med_price_by_district is not None:
            X = X.merge(self.med_price_by_district, on=['DistrictId', 'Rooms'], how='left')
            X.fillna(self.med_price_by_district_median, inplace=True)
        if self.med_price_by_floor_year is not None:
            X = X.merge(self.med_price_by_floor_year, on=['year_cat', 'floor_cat'], how='left')
            X.fillna(self.med_price_by_floor_year_median, inplace=True)
        return X
    
    def floor_to_cat(self, X):
        X['floor_cat'] = 0
        X.loc[X['Floor'] == 1, 'floor_cat'] = 1  
        X.loc[X['Floor'] == 2, 'floor_cat'] = 2
        X.loc[(X['Floor'] > 2) & (X['Floor'] <= 7), 'floor_cat'] = 3
        X.loc[(X['Floor'] > 7) & (X['Floor'] <= 15), 'floor_cat'] = 4
        X.loc[X['Floor'] > 15, 'floor_cat'] = 5
        X.loc[X['Floor'] == X['HouseFloor'], 'floor_cat'] = 6
        return X

    def year_to_cat(self, X):
        X['year_cat'] = 0
        X.loc[X['HouseYear'] <= 1957, 'year_cat'] = 1
        X.loc[(X['HouseYear'] > 1957) & (X['HouseYear'] <= 1968), 'year_cat'] = 2
        X.loc[(X['HouseYear'] > 1968) & (X['HouseYear'] <= 1975), 'year_cat'] = 3
        X.loc[(X['HouseYear'] > 1975) & (X['HouseYear'] <= 1990), 'year_cat'] = 4
        X.loc[(X['HouseYear'] > 1990) & (X['HouseYear'] <= 2009), 'year_cat'] = 5
        X.loc[(X['HouseYear'] > 2009), 'year_cat'] = 6
        return X

"""###2.7 Feature Standartizator <a class='anchor' id='standartizator'>"""

class FeatureStandartizator():
    """Стандартизация всех признаков"""
    def __init__(self):
        self.standard_type = None
    
    def transform(self, X, method='standard'):
      df = X.copy()
      all_feature_names = list(df.columns)
      feature_names_for_stand = df[all_feature_names].select_dtypes(include=['float64', 'float32', 'float16']).columns.tolist()
      self.standard_type = method
      assert self.standard_type in ['standard', 'robust'], 'Неверно указан метод'
      if self.standard_type=='standard':
        scaler = StandardScaler()
        stand_features = scaler.fit_transform(df[feature_names_for_stand])
      elif self.standard_type == 'robust':
        scaler = RobustScaler()
        stand_features = scaler.fit_transform(df[feature_names_for_stand])
      else:
        print('Error')
      df[feature_names_for_stand] = pd.DataFrame(stand_features, columns=feature_names_for_stand)
      return df

"""###2.8 Отбор признаков <a class='anchor' id='feature_selection'>"""

train_df.columns.tolist()

feature_names = ['Rooms', 'Square', 'LifeSquare', 'KitchenSquare', 'Floor', 'HouseFloor', 'HouseYear',
                 'Ecology_1', 'Ecology_2', 'Ecology_3', 'Social_1', 'Social_2', 'Social_3',
                 'Helthcare_2', 'Shops_1', 'Shops_2']

new_feature_names = ['DistrictSize', 'IsDistrictLarge', 'MedPriceByDistrict', 'DistrictAge',
                     'IsDistrictNew', 'MedPriceByFloorYear',
                     'LifeSquareFrac', 'KitchenSquareFrac', 'LifeKitchenBalance']

#new_feature_names = ['DistrictSize', 'IsDistrictLarge', 'DistrictAge',
#                     'IsDistrictNew', 'floor_cat', 'year_cat', 'MedPriceByFloorYear',
#                     'LifeSquareFrac', 'KitchenSquareFrac', 'LifeKitchenBalance']

target_name = 'Price'

"""##3. Создание и обучение модели <a class='anchor' id='ML'>

### 3.1 Разбиение на train и test  <a class='anchor' id='split'>
"""

train_df = pd.read_csv(TRAIN_DATASET_PATH)
test_df = pd.read_csv(TEST_DATASET_PATH)

X = train_df.drop(columns=target_name)
y = train_df[target_name]

X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, shuffle=True, random_state=21)

preprocessor = DataPreprocessing()
preprocessor.fit(X_train)

X_train = preprocessor.transform(X_train)
X_valid = preprocessor.transform(X_valid)
test_df = preprocessor.transform(test_df)

"""### 3.2 Генерация признаков <a class='anchor' id='ferure_gen'>"""

features_gen = FeatureGenetator()
features_gen.fit(X_train, y_train)

X_train = features_gen.transform(X_train)
X_valid = features_gen.transform(X_valid)
test_df = features_gen.transform(test_df)

test_df.head()

X_train = X_train[feature_names + new_feature_names]
X_valid = X_valid[feature_names + new_feature_names]
test_df = test_df[feature_names + new_feature_names]

X_train.isna().sum().sum(), X_valid.isna().sum().sum(), test_df.isna().sum().sum()

test_df.head(10)

"""###3.3 Стандартизация признаков"""

features_stand = FeatureStandartizator()
method1 = 'robust'
method2 = 'standard'
X_train = features_stand.transform(X_train, method=method1)
X_valid = features_stand.transform(X_valid, method=method1)
test_df = features_stand.transform(test_df, method=method1)

"""### 3.4 Построение моделей <a class='anchor' id='modeling'>

####**Линейная регрессия**
"""

lr_model = LinearRegression()
lr_model.fit(X_train, y_train)

y_train_preds = lr_model.predict(X_train)
y_valid_preds = lr_model.predict(X_valid)

evaluate_preds(y_train, y_train_preds, y_valid, y_valid_preds)

"""####**Решающее дерево**"""

dt_model = DecisionTreeRegressor()
dt_model.fit(X_train, y_train)

y_train_preds = dt_model.predict(X_train)
y_valid_preds = dt_model.predict(X_valid)

evaluate_preds(y_train, y_train_preds, y_valid, y_valid_preds)

"""####**Gradient Boosting**"""

gb_model = GradientBoostingRegressor()
gb_model.fit(X_train, y_train)

y_train_preds = gb_model.predict(X_train)
y_valid_preds = dt_model.predict(X_valid)

evaluate_preds(y_train, y_train_preds, y_valid, y_valid_preds)

"""####**Случайный лес**"""

rf_model = RandomForestRegressor()
rf_model.fit(X_train, y_train)

y_train_preds = rf_model.predict(X_train)
y_valid_preds = rf_model.predict(X_valid)

evaluate_preds(y_train, y_train_preds, y_valid, y_valid_preds)

"""####**Выбираем метод "случайного леса".**

###3.5 Подбор параметров <a class='anchor' id='tune'>
"""

'''params = {'max_features':[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14], 
          'max_depth':[5, 10, 15, 20, 25],
          'n_estimators': [100, 200, 400, 800, 1600],
          'random_state':[10, 21, 42, 84],
          'min_samples_leaf':[10, 50, 100, 200, 400]}

gs = GridSearchCV(rf_model, params, 
                  scoring='r2', # метрика 
                  cv=KFold(n_splits=4,   # k (кол-во разбиений/итераций) в кросс-валидации
                           random_state=21, 
                           shuffle=True),
                  n_jobs=-1
                  )
gs.fit(X_train, y_train)

y_train_preds = gs.predict(X_train)
y_valid_preds = gs.predict(X_valid)

evaluate_preds(y_train, y_train_preds, y_valid, y_valid_preds)'''

#gs.best_params_

"""**Подбор дал параметры 'max_depth'=15, 'max_features'=8**

###3.6 Итоговая модель <a class='anchor' id='choosen_one'>
"""

final_model = RandomForestRegressor(max_depth=15, max_features=10)
final_model.fit(X_train, y_train)

y_train_preds = final_model.predict(X_train)
y_valid_preds = final_model.predict(X_valid)

evaluate_preds(y_train, y_train_preds, y_valid, y_valid_preds)

cv_score = cross_val_score(final_model, X_train, y_train, scoring='r2', cv=KFold(n_splits=4, shuffle=True, random_state=21))
cv_score

feature_importances = pd.DataFrame(zip(X_train.columns, final_model.feature_importances_), 
                                   columns=['feature_name', 'importance'])

feature_importances.sort_values(by='importance', ascending=False)

"""## 4. Обработка тестовых данных <a class='anchor' id='real_work'>"""

submit = pd.read_csv('/content/drive/My Drive/_ML/GB/5_py_alg/webinar6/sample_submission.csv')
submit.head()

predictions = final_model.predict(test_df)
predictions

test_df.head()

submit['Price'] = predictions
submit.head()

submit.to_csv('/content/drive/My Drive/_ML/GB/5_py_alg/webinar6/2021.10.30_v4_GB_submission.csv', index=False, sep=',')

